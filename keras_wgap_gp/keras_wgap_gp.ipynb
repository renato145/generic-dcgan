{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_RATIO = 5\n",
    "GRADIENT_PENALTY_WEIGHT = 10\n",
    "OUTPUT_SAMPLES = 'imgs'\n",
    "OUTPUT_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = '/home/m20163692/data/lsun'\n",
    "data = datasets.LSUN(db_path=PATH, classes=['church_outdoor_train'],\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Scale(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]))\n",
    "\n",
    "minibatches_size = BATCH_SIZE * TRAINING_RATIO\n",
    "dataloader = torch.utils.data.DataLoader(data, minibatches_size, True, num_workers=8)\n",
    "\n",
    "def get_batch():\n",
    "    x = next(iter(dataloader))[0]\n",
    "    x = x.transpose(1, 3).transpose(1,2).numpy()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import models; importlib.reload(models)\n",
    "from models import make_generator, make_discriminator\n",
    "import gan_utils; importlib.reload(gan_utils)\n",
    "from gan_utils import build_gan_arch, generate_images, save_img, save_weights, show\n",
    "\n",
    "generator = make_generator()\n",
    "discriminator = make_discriminator()\n",
    "discriminator_model, generator_model = build_gan_arch(discriminator, generator,\n",
    "                                                      BATCH_SIZE, GRADIENT_PENALTY_WEIGHT)\n",
    "\n",
    "# We make three label vectors for training. positive_y is the label vector for real samples, with value 1.\n",
    "# negative_y is the label vector for generated samples, with value -1. The dummy_y vector is passed to the\n",
    "# gradient_penalty loss function and is not used.\n",
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log files\n",
    "def write_generator_loss(file, v):\n",
    "    lines = ''\n",
    "    if not os.path.exists(file):\n",
    "        lines += 'generator_loss\\n'\n",
    "    lines += f'{v}\\n'\n",
    "    with open(file, 'a') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "def write_discriminator_loss(file, v):\n",
    "    lines = ''\n",
    "    if not os.path.exists(file):\n",
    "        lines += 'wgp_loss, disc_real, disc_fake, gp\\n'\n",
    "    lines += ', '.join('%f' % i for i in v)\n",
    "    lines += '\\n'\n",
    "    with open(file, 'a') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "discriminator_log_file = os.path.join(OUTPUT_DATA, 'discriminator_log.csv')\n",
    "generator_log_file = os.path.join(OUTPUT_DATA, 'generator_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  1972\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "266/394\r"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "# get the highest sampled epoch\n",
    "last_epoch = [int(f.split('_')[1].split('.')[0]) for f in os.listdir('imgs/') if f[-4:] == '.png']\n",
    "if len(last_epoch) == 0:\n",
    "    epochs_range = range(epochs)\n",
    "else:\n",
    "    last_epoch = np.max(last_epoch)\n",
    "    epochs_range = range(last_epoch+1, epochs+last_epoch+1)\n",
    "\n",
    "print('Number of batches: ', int(data.length // BATCH_SIZE))\n",
    "for epoch in epochs_range:\n",
    "    print('Epoch: ', epoch)\n",
    "    iters = int(data.length // minibatches_size)\n",
    "    for i in range(iters):\n",
    "        print(f'{i+1}/{iters}', end='\\r')\n",
    "        discriminator_minibatches = get_batch()\n",
    "        for j in range(TRAINING_RATIO):\n",
    "            image_batch = discriminator_minibatches[j * BATCH_SIZE:(j + 1) * BATCH_SIZE]\n",
    "            noise = np.random.rand(BATCH_SIZE, 128).astype(np.float32)\n",
    "            discriminator_loss = discriminator_model.train_on_batch([image_batch, noise],\n",
    "                                                                    [positive_y, negative_y, dummy_y])\n",
    "            write_discriminator_loss(discriminator_log_file, discriminator_loss)\n",
    "            \n",
    "        noise = np.random.rand(BATCH_SIZE, 128).astype(np.float32)\n",
    "        generator_loss = generator_model.train_on_batch(noise, positive_y)\n",
    "        write_generator_loss(generator_log_file, generator_loss)\n",
    "    \n",
    "    save_weights(discriminator, generator)\n",
    "    generate_images(generator, OUTPUT_SAMPLES, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_weights(discriminator, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_images(generator, mode='show')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
